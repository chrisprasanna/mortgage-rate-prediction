{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac79309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cpras\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'mortgage rates' news from 10/12/2024 to 04/10/2025\n",
      "Fetching results...\n",
      "Found 10 results, converting to dataframe\n",
      "Columns in results: ['title', 'media', 'date', 'datetime', 'desc', 'link', 'img']\n",
      "Sample data: {'title': {0: 'Weekly Mortgage Rates Rise on Tariff Announcement'}, 'media': {0: 'Northeast Mississippi Daily Journal'}, 'date': {0: '0 minutes ago'}, 'datetime': {0: Timestamp('2025-04-10 17:20:15.035960')}, 'desc': {0: 'A new round of taxes on imported goods has increased borrowing costs, linking global politics to your monthly payment.The average rate on the 30-year...'}, 'link': {0: 'https://www.djournal.com/news/national/weekly-mortgage-rates-rise-on-tariff-announcement/article_e0b9efcc-d009-53b3-bd55-5d3b8d1c3ec3.html&ved=2ahUKEwjkxdLU2s6MAxX2ETQIHfrQBQIQxfQBegQIBBAC&usg=AOvVaw39QWFJJC9WJX_zR6N-uZau'}, 'img': {0: 'data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=='}}\n",
      "Filtering by finance sources...\n",
      "Processing 1 articles...\n",
      "Processing article: https://www.foxbusiness.com/economy/mortgage-rates-4-10-25\n",
      "✅ Successfully processed: Mortgage rates tick lower for third straight week...\n",
      "Creating dataframe with 1 processed articles\n",
      "Date range in data: 2025-04-10 13:20:15.328517 to 2025-04-10 13:20:15.328517\n",
      "Performing sentiment analysis...\n",
      "Sentiment analysis complete. Raw data sample:\n",
      "                        Date  \\\n",
      "0 2025-04-10 13:20:15.328517   \n",
      "\n",
      "                                               Title  Compound  \n",
      "0  Mortgage rates tick lower for third straight week    0.0772  \n",
      "Aggregating by week...\n",
      "Weekly aggregation complete with 1 weeks of data\n",
      "Successfully retrieved sentiment data:\n",
      "            NewsSentiment  NewsPos  NewsNeg  NewsNeu  NewsCount\n",
      "Week                                                           \n",
      "2025-04-07         0.0772    0.065    0.039    0.896          1\n",
      "Shape: (1, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from newspaper import Article, Config\n",
    "from GoogleNews import GoogleNews\n",
    "from datetime import datetime, timedelta\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Set a more reasonable date range - last 6 months instead of since 2000\n",
    "end_date = datetime.today().date()\n",
    "start_date = end_date - timedelta(days=180)  # 6 months\n",
    "\n",
    "# Browser configuration\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "config = Config()\n",
    "config.browser_user_agent = user_agent\n",
    "config.request_timeout = 30\n",
    "config.fetch_images = False\n",
    "\n",
    "# Finance sources\n",
    "finance_sources = [\"reuters\", \"bloomberg\", \"cnbc\", \"yahoo\", \"fox business\", \n",
    "                   \"marketwatch\", \"wall street journal\", \"forbes\", \"business insider\"]\n",
    "\n",
    "def get_news_sentiment(topic=\"mortgage rates\"):\n",
    "    \"\"\"\n",
    "    Get news sentiment about a topic using a more robust approach.\n",
    "    \"\"\"\n",
    "    # Format dates for GoogleNews\n",
    "    start_date_str = start_date.strftime('%m/%d/%Y')\n",
    "    end_date_str = end_date.strftime('%m/%d/%Y')\n",
    "    \n",
    "    print(f\"Searching for '{topic}' news from {start_date_str} to {end_date_str}\")\n",
    "    \n",
    "    # Initialize GoogleNews and search\n",
    "    googlenews = GoogleNews(lang='en', start=start_date_str, end=end_date_str)\n",
    "    googlenews.search(topic)\n",
    "    \n",
    "    # Get results\n",
    "    print(\"Fetching results...\")\n",
    "    results = googlenews.result()\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No results found from Google News\")\n",
    "        # Try with a shorter date range\n",
    "        googlenews = GoogleNews(lang='en', period='1m')  # Try last month\n",
    "        googlenews.search(topic)\n",
    "        results = googlenews.result()\n",
    "        if not results:\n",
    "            print(\"Still no results with shorter date range\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    print(f\"Found {len(results)} results, converting to dataframe\")\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Empty dataframe after converting results\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Show available columns and sample data\n",
    "    print(f\"Columns in results: {df.columns.tolist()}\")\n",
    "    print(f\"Sample data: {df.head(1).to_dict()}\")\n",
    "    \n",
    "    # Check for media column\n",
    "    if 'media' not in df.columns:\n",
    "        print(\"No 'media' column found, skipping source filtering\")\n",
    "        filtered_df = df\n",
    "    else:\n",
    "        # Filter by source\n",
    "        print(\"Filtering by finance sources...\")\n",
    "        mask = df['media'].str.lower().apply(lambda x: any(source in str(x).lower() for source in finance_sources))\n",
    "        filtered_df = df[mask]\n",
    "        \n",
    "        if filtered_df.empty:\n",
    "            print(f\"No articles from finance sources. Using all sources instead.\")\n",
    "            filtered_df = df  # Use all results if no finance sources match\n",
    "    \n",
    "    # Process articles\n",
    "    print(f\"Processing {len(filtered_df)} articles...\")\n",
    "    records = []\n",
    "    \n",
    "    # Process a maximum of 10 articles to avoid long processing time\n",
    "    for i in filtered_df.head(10).index:\n",
    "        if 'link' not in filtered_df.columns or pd.isna(filtered_df['link'][i]):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Clean URL\n",
    "            url = filtered_df['link'][i]\n",
    "            if \"&ved=\" in url:\n",
    "                url = url.split(\"&ved=\")[0]\n",
    "                \n",
    "            print(f\"Processing article: {url}\")\n",
    "            \n",
    "            # Download and parse\n",
    "            article = Article(url, config=config)\n",
    "            article.download()\n",
    "            time.sleep(1)  # Add delay to avoid rate limiting\n",
    "            article.parse()\n",
    "            \n",
    "            # Create record\n",
    "            text = article.text if article.text else \"\"\n",
    "            summary = text[:500] if text else \"\"\n",
    "            title = article.title if article.title else \"\"\n",
    "            \n",
    "            if not text and not title:\n",
    "                print(f\"⚠️ Article had no content: {url}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"✅ Successfully processed: {title[:50]}...\")\n",
    "            \n",
    "            # Extract date from the 'datetime' column if available, otherwise use today's date\n",
    "            if 'datetime' in filtered_df.columns and pd.notna(filtered_df['datetime'][i]):\n",
    "                article_date = filtered_df['datetime'][i]\n",
    "            else:\n",
    "                article_date = datetime.now()  # Use current date if no date is available\n",
    "                \n",
    "            records.append({\n",
    "                'Date': article_date,\n",
    "                'Media': filtered_df['media'][i] if 'media' in filtered_df.columns else \"Unknown\",\n",
    "                'Title': title,\n",
    "                'Summary': summary\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing article {url}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    if not records:\n",
    "        print(\"No articles were successfully processed\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Create dataframe\n",
    "    print(f\"Creating dataframe with {len(records)} processed articles\")\n",
    "    news_df = pd.DataFrame(records)\n",
    "    \n",
    "    # Convert dates - date should already be a datetime object now\n",
    "    try:\n",
    "        if 'Date' in news_df.columns:\n",
    "            # Make sure Date is a datetime object\n",
    "            if not pd.api.types.is_datetime64_any_dtype(news_df['Date']):\n",
    "                news_df['Date'] = pd.to_datetime(news_df['Date'], errors='coerce')\n",
    "                \n",
    "            news_df = news_df.dropna(subset=['Date'])\n",
    "            news_df['Week'] = news_df['Date'].dt.to_period('W').dt.start_time\n",
    "            \n",
    "            print(f\"Date range in data: {news_df['Date'].min()} to {news_df['Date'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Date processing error: {str(e)}\")\n",
    "        # If date processing fails, use current date for all articles\n",
    "        print(\"Using current date for all articles\")\n",
    "        news_df['Date'] = datetime.now()\n",
    "        news_df['Week'] = news_df['Date'].dt.to_period('W').dt.start_time\n",
    "    \n",
    "    # Sentiment analysis\n",
    "    print(\"Performing sentiment analysis...\")\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Ensure Summary column exists and has no NaNs\n",
    "    if 'Summary' not in news_df.columns:\n",
    "        print(\"No 'Summary' column found for sentiment analysis\")\n",
    "        if 'Title' in news_df.columns:\n",
    "            print(\"Using 'Title' for sentiment analysis instead\")\n",
    "            news_df['Summary'] = news_df['Title']\n",
    "        else:\n",
    "            print(\"No text available for sentiment analysis\")\n",
    "            return news_df\n",
    "    \n",
    "    news_df['Summary'] = news_df['Summary'].fillna('')\n",
    "    \n",
    "    # Calculate sentiment\n",
    "    news_df['Sentiment'] = news_df['Summary'].apply(lambda x: sia.polarity_scores(x))\n",
    "    news_df['Compound'] = news_df['Sentiment'].apply(lambda x: x['compound'])\n",
    "    news_df['Pos'] = news_df['Sentiment'].apply(lambda x: x['pos'])\n",
    "    news_df['Neg'] = news_df['Sentiment'].apply(lambda x: x['neg'])\n",
    "    news_df['Neu'] = news_df['Sentiment'].apply(lambda x: x['neu'])\n",
    "    \n",
    "    print(f\"Sentiment analysis complete. Raw data sample:\")\n",
    "    print(news_df[['Date', 'Title', 'Compound']].head())\n",
    "    \n",
    "    # Skip weekly aggregation and return raw data if needed\n",
    "    # return news_df  # Uncomment this line to return raw data instead of weekly aggregation\n",
    "    \n",
    "    # Weekly aggregation if date processing was successful and Week column exists\n",
    "    if 'Week' in news_df.columns and not news_df.empty:\n",
    "        try:\n",
    "            print(\"Aggregating by week...\")\n",
    "            weekly = news_df.groupby(\"Week\").agg(\n",
    "                NewsSentiment=(\"Compound\", \"mean\"),\n",
    "                NewsPos=(\"Pos\", \"mean\"),\n",
    "                NewsNeg=(\"Neg\", \"mean\"),\n",
    "                NewsNeu=(\"Neu\", \"mean\"),\n",
    "                NewsCount=(\"Compound\", \"count\")\n",
    "            )\n",
    "            print(f\"Weekly aggregation complete with {len(weekly)} weeks of data\")\n",
    "            return weekly\n",
    "        except Exception as e:\n",
    "            print(f\"Error in weekly aggregation: {str(e)}\")\n",
    "            print(\"Returning raw data instead\")\n",
    "            \n",
    "    # Return the processed dataframe if weekly aggregation fails or week column doesn't exist\n",
    "    return news_df\n",
    "\n",
    "# Run the analysis\n",
    "sentiment_df = get_news_sentiment(\"mortgage rates\")\n",
    "\n",
    "if not sentiment_df.empty:\n",
    "    print(\"Successfully retrieved sentiment data:\")\n",
    "    print(sentiment_df.head())\n",
    "    print(f\"Shape: {sentiment_df.shape}\")\n",
    "else:\n",
    "    print(\"No sentiment data was retrieved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
