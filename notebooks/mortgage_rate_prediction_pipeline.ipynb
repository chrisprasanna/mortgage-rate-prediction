{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06336e8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(source: str, target_col: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(source, parse_dates=['Unnamed: 0'])\n",
    "    df.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Drop target variable NaN values\n",
    "    df.dropna(subset=[target_col], inplace=True)\n",
    "\n",
    "    # Remove outliers using z-score for numerical columns\n",
    "    # numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    # df = df[(np.abs((df[numeric_cols] - df[numeric_cols].mean()) / df[numeric_cols].std()) < 3).all(axis=1)]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01b618",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c1f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['weekofyear'] = df['date'].dt.isocalendar().week\n",
    "    df['rolling_mean_3'] = df[target_col].rolling(window=3).mean()\n",
    "    df['rolling_std_3'] = df[target_col].rolling(window=3).std()\n",
    "\n",
    "    print(\"Features: \", df.columns.tolist())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d1574",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa500d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target_col: str, test_size: float = 0.2) -> tuple:\n",
    "    X = df.drop(columns=[target_col, 'date'])\n",
    "    y = df[target_col]\n",
    "    return train_test_split(X, y, test_size=test_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6352e5",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a947f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "\n",
    "    # model = xgb.XGBRegressor(\n",
    "    #     n_estimators=400,\n",
    "    #     learning_rate=0.2,\n",
    "    #     max_depth=10,\n",
    "    #     min_child_weight=9,\n",
    "    #     random_state=42\n",
    "    #     )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1bdc42",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model, X_train, y_train):\n",
    "    hyperparameter_grid = {\n",
    "        'n_estimators': [100, 400, 800],\n",
    "        'max_depth': [3, 6, 9],\n",
    "        'learning_rate': [0.05, 0.1, 0.20],\n",
    "        'min_child_weight': [1, 10, 100]\n",
    "        }\n",
    "    \n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(model, hyperparameter_grid, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best set of hyperparameters and the corresponding score\n",
    "    print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "    print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84350792",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d173bbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(f\"RMSE: {rmse:.4f}%, MAE: {mae:.4f}%, R2: {r2:.4f}\")\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4da08",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_next_week(model, df: pd.DataFrame, target_col: str):\n",
    "    last_row = df.iloc[-1:]\n",
    "    features = last_row.drop(columns=[target_col, 'date'])\n",
    "    prediction = model.predict(features)\n",
    "    print(f\"Forecasted {target_col} for next week: {prediction[0]:.4f}\")\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1378fa",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee81d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(dates, y_test, preds, forecasted_value=None):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(dates, y_test, label='Actual')\n",
    "    plt.plot(dates, preds, label='Predicted')\n",
    "    if forecasted_value is not None:\n",
    "        plt.scatter(dates.iloc[-1] + pd.DateOffset(weeks=1), forecasted_value, color='red', zorder=5)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.title('Actual vs Predicted 30Y Fixed Mortgage Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Feature Importances\")\n",
    "    sns.barplot(x=importances[indices], y=np.array(feature_names)[indices])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_scatter_predictions(y_test, preds):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=y_test, y=preds)\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Scatter plot of Actual vs Predicted')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_distribution(y_test, preds):\n",
    "    errors = y_test - preds\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(errors, bins=30, kde=True)\n",
    "    plt.xlabel('Prediction Error')\n",
    "    plt.title('Distribution of Prediction Errors')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79afa396",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pipeline\n",
    "target_col = 'MORTGAGE30US'\n",
    "\n",
    "df = load_and_preprocess_data('../data/full_mortgage_dataset.csv', target_col)\n",
    "df = create_features(df, target_col)\n",
    "X_train, X_test, y_train, y_test = split_data(df, target_col, test_size=0.2)\n",
    "test_dates = df.loc[X_test.index, 'date']\n",
    "\n",
    "model = train_model(X_train, y_train)\n",
    "preds = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "forecasted_value = forecast_next_week(model, df, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce41839",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_predictions(test_dates, y_test, preds, forecasted_value)\n",
    "plot_feature_importance(model, X_train.columns.tolist())\n",
    "plot_scatter_predictions(y_test, preds)\n",
    "plot_error_distribution(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f15ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_hyperparameters(model, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
